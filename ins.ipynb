{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random,choice\n",
    "from igraph import *\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")     \n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_index(G,node,mode = 'out'):\n",
    "    '''\n",
    "    Return h-index of a node\n",
    "    '''\n",
    "\n",
    "    sorted_neighbor_degrees = sorted(G.degree(G.neighbors(node,mode),mode),reverse=True)\n",
    "    h = 0\n",
    "    for i in range(1, len(sorted_neighbor_degrees)+1):\n",
    "        if sorted_neighbor_degrees[i-1] < i:\n",
    "            break\n",
    "        h = i\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "def hi_index(G,node,mode='out'):\n",
    "    '''\n",
    "    Return hi_index (h-index on h-index) of a node\n",
    "    '''\n",
    "\n",
    "    sorted_neighbor_h_index = sorted([h_index(G,v,mode) for v in G.neighbors(node,mode)],reverse=True)\n",
    "    h = 0\n",
    "    for i in range(1, len(sorted_neighbor_h_index)+1):\n",
    "        if sorted_neighbor_h_index[i-1] < i:\n",
    "            break\n",
    "        h = i\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inf(seeds,no_iterations):\n",
    "\n",
    "    inf_size = 0\n",
    "    inf_list = []\n",
    "    for i in range(no_iterations):\n",
    "        inf_size += len(ICM(G,seeds))\n",
    "        inf_list.append(inf_size/(i+1))\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "\n",
    "    # ax.plot([i+1 for i in range(no_iter)],inf_list)\n",
    "    # plt.show()\n",
    "\n",
    "    return inf_size/no_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(\"celegans_n306.txt\",\"d\",\"w\"),(\"USairport500.txt\",\"d\",\"w\"),\n",
    "(\"Freemans_EIES-3_n32.txt\",\"d\",\"w\"),(\"OClinks_w.txt\",\"d\",\"w\"),\n",
    "(\"USairport_2010.txt\",\"d\",\"w\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_size = 10\n",
    "no_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods\n",
    "\n",
    "# max-outdegree neighbors\n",
    "# max h2-idx neighbors\n",
    "# max p*outdegree\n",
    "# max link_pred * outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(G,source_node,k,method):\n",
    "\n",
    "    candidates = [G.vs[idx] for idx in G.neighbors(source_node,mode='out')]\n",
    "\n",
    "    if method == 'original': \n",
    "        candidates =  sorted(candidates,key = lambda node: G.es[G.get_eid(source_node,node)]['p']* node.outdegree(),reverse=True)\n",
    "        # return candidates[:min(k,len(candidates))]\n",
    "\n",
    "    elif method == 'p_l':\n",
    "        candidates = sorted(candidates,key = lambda node: G.es[G.get_eid(source_node,node)]['p_l'] * node.outdegree(),reverse= True)\n",
    "        # return candidates[:min(k,len(candidates))]\n",
    "    \n",
    "    elif method == 'degree':\n",
    "        candidates = sorted(candidates,key = lambda node: node.outdegree(),reverse= True)\n",
    "    \n",
    "    return candidates[:min(k,len(candidates))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['original','p_l','degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/rithickumar/miniforge3/envs/sn/lib/python3.10/site-packages/pandas/core/internals/blocks.py:924: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n",
      " 20%|██        | 1/5 [00:00<00:00,  5.73it/s]/Users/rithickumar/miniforge3/envs/sn/lib/python3.10/site-packages/pandas/core/internals/blocks.py:924: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n",
      " 40%|████      | 2/5 [00:02<00:04,  1.63s/it]/Users/rithickumar/miniforge3/envs/sn/lib/python3.10/site-packages/pandas/core/internals/blocks.py:924: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n",
      "/Users/rithickumar/miniforge3/envs/sn/lib/python3.10/site-packages/pandas/core/internals/blocks.py:924: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n",
      " 80%|████████  | 4/5 [00:03<00:00,  1.26it/s]/Users/rithickumar/miniforge3/envs/sn/lib/python3.10/site-packages/pandas/core/internals/blocks.py:924: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n",
      "100%|██████████| 5/5 [00:36<00:00,  7.39s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for dataset,directed,weighted in tqdm(datasets):\n",
    "    \n",
    "    df_result = pd.DataFrame(None,columns=['seed_size']+methods)\n",
    "\n",
    "    if dataset in [\"email.txt\" ,\"road.txt\" ,\"weblog.txt\" ,\"animal_interaction.txt\",\"facebook_combined.txt\"]:\n",
    "        data_file_path = os.path.join(os.pardir,os.pardir,\"data\",\"Prev Data\",dataset)\n",
    "    else:\n",
    "        data_file_path = os.path.join(os.pardir,os.pardir,\"data\",dataset)\n",
    "    \n",
    "    directed = True if directed == \"d\" else False\n",
    "    weighted = True if weighted == \"w\" else False\n",
    "\n",
    "    G = read_graph(data_file_path,directed,weighted = weighted)\n",
    "    \n",
    "    if weighted == True:\n",
    "        G.es['p'] = scale(get_true_weights(dataset,directed,data_file_path,weighted))\n",
    "    else:\n",
    "        G.es['p'] = prob_heuristics(G,\"RA\")\n",
    "\n",
    "    # df = pd.read_csv(os.path.join(os.pardir,\"Cascade_Experiments\",\"Cascade outputs\",f\"{dataset.split('.')[0]}_CP.csv\"))\n",
    "\n",
    "    G.es['p_l'] = prob_heuristics(G,\"RA\")\n",
    "    G.vs['shell'] = G.coreness(mode='out')\n",
    "    # for v in G.vs:\n",
    "    #     # v['power'] = df[df.Node == v.index]['p=Original'].values[0]\n",
    "    #     v['shell'] = G.coreness()\n",
    "    \n",
    "    # seeds_list = []\n",
    "    G.vs['h2-idx'] = [hi_index(G,node,'out') for node in G.vs]\n",
    "    \n",
    "    # new_heuristic(G)\n",
    "    # local_GSM(G)\n",
    "    # Profit_Sharing(G)\n",
    "    # GSM(G)\n",
    "    # GSM_pc(G)\n",
    "    # heuristic_2(G)\n",
    "    \n",
    "    \n",
    "    source_node = choice(G.vs)\n",
    "    # get_cost(G,source_node)\n",
    "    for method in methods:\n",
    "        seeds = get_seeds(G,source_node,seed_size,method)\n",
    "        # for i in tqdm(range(seed_size)):\n",
    "        #     df_result.at[i,'seed_size'] = i+1\n",
    "        #     # seed = max([node for node in G.vs if node not in seeds],key= lambda node:node[method])\n",
    "        #     # seeds.append(seed)\n",
    "        #     seeds \n",
    "        df_result.at[0,method] =  ([seed.index for seed in seeds],get_inf(seeds,no_iterations))\n",
    "\n",
    "        # seeds_list.append(seeds)\n",
    "    \n",
    "    results[dataset] = df_result\n",
    "\n",
    "    results[dataset].to_csv(f\"{dataset.split('.')[0]}_comp.csv\",index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77990b3d0b8ab27b18a618c2b3a9465bfe3d122fc522b12e1073bb1fc5621ade"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('sn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
